title: Kundensegmentierung mit K-Means-Clustering in Python

question: |

  Die Daten stammen aus Kaggle Seite. du findest die unter: https://www.kaggle.com/datasets/vjchoudhary7/customer-segmentation-tutorial-in-python

  ### Kontext
  Dieser Datensatz wird nur zum Erlernen der Konzepte der Kundensegmentierung erstellt, die auch als Warenkorbanalyse bezeichnet werden. Ich werde dies mithilfe der unüberwachten ML-Technik (KMeans-Clustering-Algorithmus) in der einfachsten Form demonstrieren.

  ### Inhalt
  Sie besitzen einen Supermarkt und verfügen über Mitgliedskarten über einige grundlegende Daten Ihrer Kunden wie Kundennummer, Alter, Geschlecht, Jahreseinkommen und Ausgaben-Score. Der
  Ausgaben-Score wird dem Kunden basierend auf Ihren definierten Parametern wie Kundenverhalten und Einkaufsdaten zugewiesen.

  Ein CSV-Datensatz (Mall_Customers.csv) mit den folgenden Spalten:

  CustomerID: Eindeutige Kundennummer

  Gender: Geschlecht des Kunden

  Age: Alter in Jahren

  Annual Income (k$): Jahreseinkommen in Tausend US-Dollar

  Spending Score (1-100): Skalenwert für Kundenverhalten (1 = niedrig, 100 = hoch)

  ### Problemstellung:
  Sie sind Eigentümer des Einkaufszentrums und möchten die Kunden verstehen, die sich leicht als Zielkunden zusammenführen lassen, damit das Marketingteam die nötigen Informationen erhält und die Strategie entsprechend planen kann.


  ### Zeil 

  Am Ende dieser Fallstudie können Sie die folgenden Fragen beantworten.
  1. Wie Sie mithilfe eines Algorithmus für maschinelles Lernen (KMeans Clustering) in Python auf einfachste Weise eine Kundensegmentierung erreichen.
  2. Wer sind Ihre Zielkunden, mit denen Sie eine Marketingstrategie starten können? [Einfache Konversation]
  3. Wie funktioniert die Marketingstrategie in der realen Welt?

  ###  Ihre Aufgaben:

  Laden Sie den Datensatz in ein Pandas DataFrame.

  Verschaffen Sie sich einen Überblick über die Daten:

  Zeigen Sie die ersten 5 Zeilen.

  Geben Sie die Dimensionen (Anzahl Zeilen/Spalten) aus.

  Prüfen Sie Datentypen und auf fehlende Werte.

  Wählen Sie geeignete Spalten für die Clusterbildung aus.

  Begründen Sie Ihre Auswahl.

  Bestimmen Sie die optimale Anzahl an Clustern mithilfe der Elbow-Methode.

  Trainieren Sie das K-Means-Modell mit der gefundenen Clusteranzahl.

  Visualisieren Sie die Clustereinteilung der Kunden in einem Streudiagramm.

  Interpretieren Sie die Cluster:

  Welche Gruppen von Kunden können Sie erkennen?

  Welche Cluster wären besonders interessant für Marketingzwecke?

  ### Hinweise:
  Verwenden Sie für das Clustering die Spalten „Annual Income (k$)“ und „Spending Score (1-100)“.

  Nutzen Sie zur Visualisierung matplotlib oder seaborn.

  Achten Sie auf eine sinnvolle Darstellung der Ergebnisse.

  Begründen Sie Ihre Schritte nachvollziehbar.

solution: |

  #### Abhängigkeiten importieren

  ```python
  # Abhängigkeiten importieren

  import numpy as np # für Datenmanipulation
  import pandas as pd # für Datenmanipulation
  import matplotlib.pyplot as plt # Visualisierung
  import seaborn as sns # Visualisierung
  from sklearn.cluster import KMeans #  Machine Learning
  ```
  #### Daten einlesen und ersten Überblick verschaffen

  Jetzt lesen wir die CSV-Datei in ein DataFrame ein. Danach schauen wir uns die ersten 5 Zeilen an, um die Struktur zu verstehen.
  ## Die Daten mit pandas Data Frame verbinden


  ```python
  kunden_daten = pd.read_csv("../../Data/Project 13/Mall_Customers.csv")
  ```

  #### Form und Größe der Daten prüfen

  Wie viele Kunden (Zeilen) und Merkmale (Spalten) haben wir? .shape zeigt uns das als Tupel (Zeilen, Spalten).
  ```python
    ## die ersten 5 Zeilen des Dataframe ausgeben

  kunden_daten.head(5)
  ```

  ```python
  # gebe die Anzahl der Zeilen und Spalten in der Konsole aus

  kunden_daten.shape
  ```

  #### Detaillierte Infos über den DataFrame anzeigen

  Mit .info() prüfen wir Datentypen, Speichernutzung und ob Null-Werte vorhanden sind.


  ```python
  # Gebe detailierte Infos über unsere Datenset 

  kunden_daten.info()
  ```

  #### Nach fehlenden Werten suchen
  Ein sauberes Dataset ist wichtig. Mit .isnull().sum() finden wir heraus, ob es in irgendeiner Spalte fehlende Daten gibt.

    ```python
  ## Suche nach fehlende Werte zw. Null-Werte

  # kunden_daten.isnull() #-> liefert mir den Wert (False / True) je Zelle

  kunden_daten.isnull().sum() # -> Fasst mir die Anzahl der Null-Werte je Spalte zusammen
  ```

  #### Relevante Spalten für das Clustering auswählen

  Wir möchten die Kunden nach Einkommen und Spending Score gruppieren. Diese Spalten liegen im Index [3,4].

  Nun sollen wir unsere Daten culstern. man könnte unsere Datenset nach verschieden Spalten Klustern. wir haben die Spalte CustoerID die eigentlich für die identifizierung von einzelne Kunden dient. daher macht eine Clustering nach KundenID kein sinn. Ausserdem haben wir die Spateln Geschlecht (Gender) und Alter (Age). man könnte zwar nach diese Spalten clustertn. Alleridngs wollen wir nach Jahreseinkommen und  Ausgaben-Score (Spending Score) clustern.


  ```python
  # Auswählen von Jareseinkommen Spalte und Ausgaben-Score

  X = kunden_daten.iloc[:,[3,4]].values # -> beiden Spalten werden gewählt, mir wird dann eine Array liste geliefert die aus weitere Arrays bestehen [["a1, a2"], [b1, b2]]

  print(X[0])
  ```

  #### Optimale Clusteranzahl mit Elbow-Methode bestimmen

  Wir probieren Cluster-Anzahlen von 1 bis 10 und berechnen den WCSS-Wert (Summe der Fehlerquadrate innerhalb der Cluster).
  Der Knick im Diagramm (elbow) zeigt die optimale Clusteranzahl.

    ```python
  # finde den WSS Wert für verschiedene Clutsers

  wcss = []

  for index in range(1,11):
    kamenas = KMeans(n_clusters= index, init="k-means++", random_state=42)
    kamenas.fit(X)

    wcss.append(kamenas.inertia_)
  ```


  ```python
  # plot an ellbow graph 

  sns.set()
  plt.plot(range(1,11), wcss)
  plt.title('The Elbow Point Graph')
  plt.xlabel('Number of Clusters')
  plt.ylabel('WCSS')
  plt.show()
  ```


  #### KMeans-Modell mit optimaler Clusteranzahl trainieren

  Laut Elbow-Diagramm wählen wir 5 Cluster, da der Knick bei 5 am größten ist.
  Das Modell wird trainiert, und die Clusterzugehörigkeit (Y) wird gespeichert.

  ```python
  kmeans = KMeans(n_clusters=5, init='k-means++', random_state=0)

  # return a label for each data point based on their cluster
  Y = kmeans.fit_predict(X)

  print(Y)
  ```

  #### Visualisierung der Clusterergebnisse

  Wir plotten jeden Cluster in einer anderen Farbe. Zusätzlich zeigen wir die Clusterzentren (centroids).

  ```python

  plt.figure(figsize=(8,8))
  plt.scatter(X[Y==0,0], X[Y==0,1], s=50, c='green', label='Cluster 1')
  plt.scatter(X[Y==1,0], X[Y==1,1], s=50, c='red', label='Cluster 2')
  plt.scatter(X[Y==2,0], X[Y==2,1], s=50, c='yellow', label='Cluster 3')
  plt.scatter(X[Y==3,0], X[Y==3,1], s=50, c='violet', label='Cluster 4')
  plt.scatter(X[Y==4,0], X[Y==4,1], s=50, c='blue', label='Cluster 5')

  # plot the centroids
  plt.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1], s=100, c='cyan', label='Centroids')

  plt.title('Customer Groups')
  plt.xlabel('Annual Income')
  plt.ylabel('Spending Score')
  plt.show()
    ```
