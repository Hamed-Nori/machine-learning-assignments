{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db43d468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                  # Für numerische Operationen\n",
    "import pandas as pd                # Für das Laden und Bearbeiten von Datensätzen\n",
    "import matplotlib.pyplot as plt    # Für Datenvisualisierung (Diagramme, Plots)\n",
    "import seaborn as sns              # Für statistische Visualisierungen (Heatmaps, Boxplots etc.)\n",
    "%matplotlib inline                 # Damit die Diagramme direkt im Notebook angezeigt werden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff5abad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Schleife über alle Unterverzeichnisse und Dateien im Eingabeordner\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0484634f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76566276",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = '/kaggle/input/car-evaluation-data-set/car_evaluation.csv'\n",
    "\n",
    "df = pd.read_csv(data, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c093d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view dimensions of dataset\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685d327d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview the dataset\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6e5ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class']\n",
    "\n",
    "\n",
    "df.columns = col_names\n",
    "\n",
    "col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4db2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's again preview the dataset\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab60dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d237c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class']\n",
    "\n",
    "\n",
    "for col in col_names:\n",
    "    \n",
    "    print(df[col].value_counts())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfcb81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7492d9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check missing values in variables\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a893903",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['class'], axis=1)\n",
    "\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f72403e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training and testing sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7453639f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the shape of X_train and X_test\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67aabe4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data types in X_train\n",
    "\n",
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ba30dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae00a647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import category encoders\n",
    "\n",
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b30df15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode categorical variables with ordinal encoding\n",
    "\n",
    "encoder = ce.OrdinalEncoder(cols=['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety'])\n",
    "\n",
    "\n",
    "X_train = encoder.fit_transform(X_train)\n",
    "\n",
    "X_test = encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e393e7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49031d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d097d4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Random Forest classifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "\n",
    "# instantiate the classifier \n",
    "\n",
    "rfc = RandomForestClassifier(random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "# fit the model\n",
    "\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "# Predict the Test set results\n",
    "\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# Check accuracy score \n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Model accuracy score with 10 decision-trees : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309b3cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the classifier with n_estimators = 100\n",
    "\n",
    "rfc_100 = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "# fit the model to the training set\n",
    "\n",
    "rfc_100.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "# Predict on the test set results\n",
    "\n",
    "y_pred_100 = rfc_100.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# Check accuracy score \n",
    "\n",
    "print('Model accuracy score with 100 decision-trees : {0:0.4f}'. format(accuracy_score(y_test, y_pred_100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966aca47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the classifier with n_estimators = 100\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "# fit the model to the training set\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb26d729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the feature scores\n",
    "\n",
    "feature_scores = pd.Series(clf.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "\n",
    "feature_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5019dd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a seaborn bar plot\n",
    "\n",
    "sns.barplot(x=feature_scores, y=feature_scores.index)\n",
    "\n",
    "\n",
    "\n",
    "# Add labels to the graph\n",
    "\n",
    "plt.xlabel('Feature Importance Score')\n",
    "\n",
    "plt.ylabel('Features')\n",
    "\n",
    "\n",
    "\n",
    "# Add title to the graph\n",
    "\n",
    "plt.title(\"Visualizing Important Features\")\n",
    "\n",
    "\n",
    "\n",
    "# Visualize the graph\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871a8131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare feature vector and target variable\n",
    "\n",
    "X = df.drop(['class', 'doors'], axis=1)\n",
    "\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849026b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training and testing sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c32a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode categorical variables with ordinal encoding\n",
    "\n",
    "encoder = ce.OrdinalEncoder(cols=['buying', 'maint', 'persons', 'lug_boot', 'safety'])\n",
    "\n",
    "\n",
    "X_train = encoder.fit_transform(X_train)\n",
    "\n",
    "X_test = encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb83f3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the classifier with n_estimators = 100\n",
    "\n",
    "clf = RandomForestClassifier(random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "# fit the model to the training set\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predict on the test set results\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# Check accuracy score \n",
    "\n",
    "print('Model accuracy score with doors variable removed : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2591eb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the Confusion Matrix and slice it into four pieces\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('Confusion matrix\\n\\n', cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a881857",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
